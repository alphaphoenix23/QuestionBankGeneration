**Introduction**

Question paper generation is a critical aspect of educational
assessment, influencing the effectiveness and fairness of examinations.
Crafting well-structured and diverse sets of questions requires careful
consideration of various factors, including the educational objectives,
difficulty levels, and coverage of the curriculum. In recent years,
advancements in technology have transformed the landscape of question
paper generation. Traditional methods often relied on manual creation, a
time-consuming and labor-intensive process. However, with the
integration of artificial intelligence and machine learning techniques,
there has been a paradigm shift towards automated question paper
generation. This introduction explores the evolving landscape of
question paper generation, delving into the current methods and
technological innovations that contribute to more efficient, dynamic,
and customized examination assessments.

**Problem Statement**

Given the curriculum for an exam as input, the question paper generator
must provide multiple question papers and answers, each with valid
questions with answers bound by the curriculum. The professor should be
able to interact with the platform, upload syllabus content and review
question papers and their answers.

**Approach**

The approach to the problem statement consists of the following steps:

1.  Data Collection and Preparation

2.  Building RAG framework

3.  Testing and Evaluation of Model

4.  User Interface Platform Development

5.  Testing UI Platform

***Data Collection and Preparation***

1.  A domain-specific archive will be established for a standard method
    > of data collection. Professors will be required to submit past
    > question papers, evaluation schemes, course content, etc to the
    > archive.

2.  The archive will be accessible through a Typescript based website
    > where data can be uploaded, reviewed and edited.

3.  This data will be organized by time and domains and will be
    > available for filtering and sorting through various features.

4.  The data will be further used for RAG.

***Building RAG Framework***

RAG is an AI framework that improves the accuracy and reliability of
large language models (LLMs) by grounding them in external knowledge
bases. LLMs can be inconsistent and prone to errors, lacking true
understanding of word meaning. RAG addresses these issues by providing
access to up-to-date facts and verifiable sources, increasing user
trust.

1.  An unstructured Database is generated in the form of Vector
    > databases by improving on existing techniques of generating
    > embeddings from text.

2.  A knowledge graph, or a structured database, is generated by
    > improving on existing techniques to plot entity relationships.

3.  These databases are collectively plugged into the Question and
    > Answer Generation model (LLM).

4.  User Input as natural language is processed to query the databases
    > and the input, along with retrieved data, is used by the LLM to
    > generate output.

***Testing and Evaluation of Model***

1.  Above established architecture is then tested in multiple phases,
    > both automated and manual, to ensure lack of potential errors and
    > unexpected responses.

2.  It is then evaluated using qualitative methods (such as checking for
    > hallucinations) and quantitative methods (such as accuracy
    > metrics).

3.  Lastly, the framework is subjected to user testing through a review
    > process with faculty.

***User Interface Platform Development***

The Framework will be accessible to all faculty through a platform
consisting of a dashboard with question paper metrics, Import and export
options for curriculum content and question answer sets respectively,
and a conversational bot for any user input or queries.

The platform will be developed using JavaScript and Python.

***Testing UI Platform***

Lastly, the UI platform will be thoroughly tested in stages, during and
after development.

1.  Unit testing, Regression testing will be carried out throughout the
    > development process.

2.  Environment testing will be performed post development to ensure
    > proper functionality in user environment.

3.  The platform will then be reviewed by faculty for beta testing and
    > any necessary changes.

**LLM Used for Task**

The LLM used for above task will be an improved version of [[Question
and Answer Generator
(QAG)]{.underline}](https://github.com/keshavaspanda/lm-question-generation).

**Conclusion**

In conclusion, this comprehensive approach to question paper generation,
encompassing data collection, the development of the RAG framework,
testing and evaluation, user interface platform creation, and the
utilization of a powerful Language Model (LLM), represents a significant
stride towards revolutionizing the educational assessment landscape. The
integration of cutting-edge technologies, such as artificial
intelligence and machine learning, is poised to enhance the efficiency
and customization of examination assessments. The RAG framework, with
its grounding in external knowledge bases and its ability to improve the
accuracy of large language models, holds promise in mitigating the
inconsistencies and errors often associated with traditional question
paper generation. The user interface platform, designed with the faculty
in mind, ensures a user-friendly experience, allowing seamless
interaction with the system for curriculum uploads, question paper
reviews, and more. Through rigorous testing and evaluation, both
automated and user-centric, the reliability of the framework is
affirmed, paving the way for a transformative tool in the hands of
educators. As this approach unfolds, it promises to streamline and
elevate the process of question paper generation, ultimately
contributing to more effective and fair educational assessments.
